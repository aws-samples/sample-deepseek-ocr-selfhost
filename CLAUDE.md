# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

DeepSeek OCR Pipeline - A production-ready OCR solution using DeepSeek-OCR with AWS CDK, ECS on GPU instances (g4dn.xlarge), and A2I human review workflows. This is a hybrid architecture combining the Bogdanovich77 DeepSeek-OCR Docker implementation with AWS orchestration.

## Common Commands

```bash
# Install dependencies
npm install

# Build (compile + lint + synth)
npm run build

# Run linting
npm run eslint

# Synthesize CDK templates
npm run synth

# Deploy to dev environment (requires STAGE=dev env var)
STAGE=dev npm run deploy:dev

# Deploy with specific profile
npm run deploy-dev      # uses --profile dev
npm run deploy-prod     # uses --profile prod

# Build Docker image locally
npm run build-docker

# View CDK diff
npm run diff

# Watch mode (hotswap deploys)
npm run watch

# Destroy dev stacks
STAGE=dev npm run destroy:dev
```

## Architecture

### CDK Stage Structure

The app uses a single stage (`DevStage`) defined in `src/lib/stages.ts` that orchestrates six stacks:

1. **KmsStack** - Encryption keys for all resources
2. **NetworkingStack** - VPC with public/private/isolated subnets across 3 AZs
3. **EcsStack** - GPU cluster with g4dn.xlarge instances, ALB, auto-scaling (1-10 instances)
4. **S3Stack** - File storage bucket with KMS encryption
5. **LambdasStack** - Processing Lambda functions (start processing handler)
6. **ApiGatewayStack** - REST API with VPC integration to ECS

Stack dependencies: EcsStack depends on KmsStack and NetworkingStack.

### Docker Container (`docker/`)

Custom DeepSeek-OCR implementation based on vLLM OpenAI image. Key customizations:
- `custom_config.py`, `custom_image_process.py`, `custom_deepseek_ocr.py` - Fixed prompt parameter bugs
- `start_server.py` - FastAPI server with `/health`, `/ocr/pdf`, `/ocr/image`, `/ocr/batch` endpoints
- Model downloads from HuggingFace at runtime (`deepseek-ai/DeepSeek-OCR`)

### Key Construct: `DeepSeekOcrEc2GpuConstruct`

Located in `src/constructs/deepseek-ocr-ecs.ts`, this is the core infrastructure construct managing:
- ECS cluster with GPU-optimized AMI
- Auto-scaling group with optional spot instance support
- Application Load Balancer with health checks on port 8000
- Task definition with 1 GPU, 14GB memory, 3.75 vCPU allocation
- Model cache persistence via host volume mount at `/mnt/ecs-data/models`

## Environment Variables

Required:
- `STAGE` - Must be set for deployment (e.g., `dev`)
- `CDK_DEFAULT_REGION` - AWS region (defaults to `us-east-1`)
- `CDK_DEFAULT_ACCOUNT` - AWS account ID

Container environment:
- `MODEL_PATH=deepseek-ai/DeepSeek-OCR` - HuggingFace repository ID
- `GPU_MEMORY_UTILIZATION=0.85`
- `MAX_CONCURRENCY=5`

## Deployment Script

`scripts/deploy-ocr-update.sh` provides automated deployment:
1. Zips and uploads Docker source to S3
2. Triggers CodeBuild to build and push to ECR
3. Forces new ECS deployment
4. Monitors rollout and runs health check

## Projen

This project is managed by Projen. Configuration is in `.projenrc.ts`. After modifying `.projenrc.ts`, run `npx projen` to regenerate project files. Do not manually edit generated files (marked with `// ~~ Generated by projen`).
